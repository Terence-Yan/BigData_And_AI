#### 1.Hive的本质
```
hive的本质是，在hive数据表与已经存在的结构化的数据文件之间建立映射关系。映射建立成功之后，
就可以通过SQL来分析这些结构化的数据文件，避免了写MR程序。
```
#### 2.Hive数据库系统与文件的对应关系
```
hive数据库       对应    /usr/hive/warehouse(HDFS)目录下的一个文件夹
    数据表       对应    所在数据库的目录下的子文件夹
表中的数据       对应    所在数据表目录下的文件
```

#### 3.Hive的建表语句
```
创建hive表时，可能还需要指定分隔符，否则数据可能会加载不成功：
   create table test(id int, name string , age int) row format delimited fields terminated by ',';
   其中，表名--test，字段--id,name,age。
   delimited关键字表示使用的是内置分隔符。
```

#### 4.复杂数据类型指定分隔符
```
HQL建表语句：
create table t_hobby(id int,name string,hobby map<string, string>) 
row format delimited fields terminated by ',' 
collection items terminated by '-' 
map keys terminated by ':';
示例数据：
   1,Tom,打游戏:非常喜欢-篮球:喜欢
   2,Lucy,唱歌:非常喜欢-跳舞:喜欢-游泳:一般
```

#### 5.建表注意事项
```
1.建表的时候一定要根据所对应的结构化数据文件的分隔符来指定建表分隔符；
2.建表的字段的个数及字段类型要与对应的结构化数据文件中的数据格式匹配。
```

#### 6.关于Hive的默认分隔符
```
1.hive建表的时候默认的分隔符是'\001'，若在建表的时候没有指定分隔符，load文件的时候文件的分隔符就被默认为是'\001';若文件分隔符
不是'\001'，程序不会报错，但表查询的结果会全部是“NULL”。
2.用vi编辑器，先Ctrl+v,然后Ctrl+a即可输入'\001'-------^A
```

#### 7.Hive读写文件的机制
```
1.Hive读取文件的机制：首先调用InputFormat(默认TextInputFormat)，返回一条一条的记录(默认是一行对应一条记录)。然后调用
  SerDe(默认是LazySimpleSerDe)的Deserializer，将一条记录切分为各个字段(默认分隔符--'\001')。
2.Hive写文件的机制：将Row写入文件时，主要调用OutputFormat、SerDe的Serializer,顺序与读取相反。
```

#### 8.Partitioned By与分区表
```
1.在Hive的select查询中一般会扫描整个表的内容，会消耗很多时间做没有必要的工作。有时候只需扫描表中关心的某一特定部分的数据，因此
  hive在建表时,通过关键字partitioned by 引入了分区(partition)的概念。
2.分区表指的是在创建表的时候指定的partition的分区空间。一个表可以拥有一个或多个分区，每个分区以文件夹的形式单独存在于所属表文件夹的
  目录下。表和列名不区分大小写。分区是以字段的形式在表结构中存在，通过describe table 命令可以查看到该字段存在，但是该字段不存放实际
  的数据内容，仅仅是分区的表示。
3.HQL建表语句示例：create table t_employee(id int,name string) partitioned by(country string) 
  row format delimited fields terminated by ',';
  对应数据文件的数据格式：
  1,Tony
  2,李明
4.注意事项：a).用于分区的字段不能是数据表中已经存在的字段；b).分区字段是一个虚拟字段，不存放任何数据；c).分区字段的值是在装载表的
  分区数据时指定的：Load DATA Local inpath '/usr/hive/a.txt' into table test partition(country='USA'); . 
5.多分区表，HQL建表语句示例：create table t_employee(id int,name string) partitioned by(day string,hour string) 
  row format delimited fields terminated by ',';
6.分区表字段在HDFS上的体现是所属数据表的文件夹目录下会依据分区字段依次建立子文件夹，建立规则是左边的分区字段所对应的文件夹目录
  是相邻的右边的分区字段所对应文件夹的父目录。
```

#### 9.Clustered By...INTO num_buckets BUCKETS与分桶表
```
1.创建分桶表之前，应该先开启分桶功能，默认是关闭的。
  指定开启分桶功能： set hive.enforce.bucketing=true;
                   set mapreduce.job.reduces=4;
  HQL建表语句示例：create table t_stu(sNo int,sName string,sSex string,sAge int,sDept string) clustered by(sNo) 
  into 4 buckets
  row format delimited fields terminated by ',';
2.分桶表(分簇表)创建的时候，分桶字段必须是数据表中已定义的字段
3.不能使用load data方式导入分桶数据
4.加载分桶数据的HQL语句示例：insert overwrite table t_stu select * from student clustered by(sNo);
  导入分桶数据步骤：1.创建中间结果表student，将原始文件数据装载进该表；2.通过insert...select...语句将分桶后的数据加载进目标表t_stu。
5.分桶对应的是MapReduce任务中的partitioner.
```

#### 10.对数据分桶的目的与作用
* 对于每一个表或者分区，Hive可以进一步组织成桶，也就说桶是更为细粒度的数据范围划分。Hive也是针对某一列进行分桶的组织。Hive采用对列值哈希，
然后除以桶的个数再求余的方式决定该条记录存放在哪个桶当中。
* 把表或分区组织成桶有两个理由：</br>
  (1).获得更高的查询处理效率。桶为表加上了额外的结构，Hive在处理有些查询时能利用这个结构。具体而言，连接两个在(包含连接的列)相同列上划分了桶的表，
  可以使用Map 端连接(Map-side join)高效的实现，比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作，那么将保存相同列值
  的桶进行JOIN操作就可以，可以大大减少JOIN的数据量。</br>
  (2).使取样(sampling)更高效。在处理大规模数据集时，在开发和修改查询阶段，如果能在数据集的一小部分上试运行查询，会带来很多方便。
  





