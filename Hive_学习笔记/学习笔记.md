#### 1.Hive的本质
```
hive的本质是，在hive数据表与已经存在的结构化的数据文件之间建立映射关系。映射建立成功之后，
就可以通过SQL来分析这些结构化的数据文件，避免了写MR程序。
```
#### 2.Hive数据库系统与文件的对应关系
```
hive数据库       对应    /usr/hive/warehouse(HDFS)目录下的一个文件夹
    数据表       对应    所在数据库的目录下的子文件夹
表中的数据       对应    所在数据表目录下的文件
```

#### 3.Hive的建表语句
```
创建hive表时，可能还需要指定分隔符，否则数据可能会加载不成功：
   create table test(id int, name string , age int) row format delimited fields terminated by ',';
   其中，表名--test，字段--id,name,age。
   delimited关键字表示使用的是内置分隔符。
```

#### 4.复杂数据类型指定分隔符
```
HQL建表语句：
create table t_hobby(id int,name string,hobby map<string, string>) 
row format delimited fields terminated by ',' 
collection items terminated by '-' 
map keys terminated by ':';
示例数据：
   1,Tom,打游戏:非常喜欢-篮球:喜欢
   2,Lucy,唱歌:非常喜欢-跳舞:喜欢-游泳:一般
```

#### 5.建表注意事项
```
1.建表的时候一定要根据所对应的结构化数据文件的分隔符来指定建表分隔符；
2.建表的字段的个数及字段类型要与对应的结构化数据文件中的数据格式匹配。
```

#### 6.关于Hive的默认分隔符
```
1.hive建表的时候默认的分隔符是'\001'，若在建表的时候没有指定分隔符，load文件的时候文件的分隔符就被默认为是'\001';若文件分隔符
不是'\001'，程序不会报错，但表查询的结果会全部是“NULL”。
2.用vi编辑器，先Ctrl+v,然后Ctrl+a即可输入'\001'-------^A
```

#### 7.Hive读写文件的机制
```
1.Hive读取文件的机制：首先调用InputFormat(默认TextInputFormat)，返回一条一条的记录(默认是一行对应一条记录)。然后调用
  SerDe(默认是LazySimpleSerDe)的Deserializer，将一条记录切分为各个字段(默认分隔符--'\001')。
2.Hive写文件的机制：将Row写入文件时，主要调用OutputFormat、SerDe的Serializer,顺序与读取相反。
```

#### 8.Partitioned By与分区表
```
1.在Hive的select查询中一般会扫描整个表的内容，会消耗很多时间做没有必要的工作。有时候只需扫描表中关心的某一特定部分的数据，因此
  hive在建表时,通过关键字partitioned by 引入了分区(partition)的概念。
2.分区表指的是在创建表的时候指定的partition的分区空间。一个表可以拥有一个或多个分区，每个分区以文件夹的形式单独存在于所属表文件夹的
  目录下。表和列名不区分大小写。分区是以字段的形式在表结构中存在，通过describe table 命令可以查看到该字段存在，但是该字段不存放实际
  的数据内容，仅仅是分区的表示。
3.HQL建表语句示例：create table t_employee(id int,name string) partitioned by(country string) 
  row format delimited fields terminated by ',';
  对应数据文件的数据格式：
  1,Tony
  2,李明
4.注意事项：a).用于分区的字段不能是数据表中已经存在的字段；b).分区字段是一个虚拟字段，不存放任何数据；c).分区字段的值是在装载表的
  分区数据时指定的：Load DATA Local inpath '/usr/hive/a.txt' into table test partition(country='USA'); . 
5.多分区表，HQL建表语句示例：create table t_employee(id int,name string) partitioned by(day string,hour string) 
  row format delimited fields terminated by ',';
6.分区表字段在HDFS上的体现是所属数据表的文件夹目录下会依据分区字段依次建立子文件夹，建立规则是左边的分区字段所对应的文件夹目录
  是相邻的右边的分区字段所对应文件夹的父目录。
```

#### 9.Clustered By...INTO num_buckets BUCKETS与分桶表
```
1.创建分桶表之前，应该先开启分桶功能，默认是关闭的。
  指定开启分桶功能： set hive.enforce.bucketing=true;
                   set mapreduce.job.reduces=4;
  HQL建表语句示例：create table t_stu(sNo int,sName string,sSex string,sAge int,sDept string) clustered by(sNo) 
  into 4 buckets
  row format delimited fields terminated by ',';
2.分桶表(分簇表)创建的时候，分桶字段必须是数据表中已定义的字段
3.不能使用load data方式导入分桶数据
4.加载分桶数据的HQL语句示例：insert overwrite table t_stu select * from student clustered by(sNo);
  导入分桶数据步骤：1.创建中间结果表student，将原始文件数据装载进该表；2.通过insert...select...语句将分桶后的数据加载进目标表t_stu。
5.分桶对应的是MapReduce任务中的partitioner.
6.分桶表体现在对应的结构化数据文件上是，将其所对应的一个数据文件拆分成更小的几个数据文件。
```

#### 10.对数据分桶的目的与作用
* 对于每一个表或者分区，Hive可以进一步组织成桶，也就说桶是更为细粒度的数据范围划分。Hive也是针对某一列进行分桶的组织。Hive采用对列值哈希，
然后除以桶的个数再求余的方式决定该条记录存放在哪个桶当中。
* 把表或分区组织成桶有两个理由：</br>
  (1).获得更高的查询处理效率。桶为表加上了额外的结构，Hive在处理有些查询时能利用这个结构。具体而言，连接两个在(包含连接的列)相同列上划分了桶的表，
  可以使用Map 端连接(Map-side join)高效的实现，比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作，那么将保存相同列值
  的桶进行JOIN操作就可以，可以大大减少JOIN的数据量。</br>
  (2).使取样(sampling)更高效。在处理大规模数据集时，在开发和修改查询阶段，如果能在数据集的一小部分上试运行查询，会带来很多方便。
  
#### 11.EXTERNAL关键字与外部表
* EXTERNAL关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的存储路径(通过LOCATION关键字指定).
  HQL创建外部表语句示例：
  ```
  create external table t_stu(sNo int,sName string,sSex string,sAge int,sDept string)    
  row format delimited fields  terminated by ',' location '/tmp/hive';
  注：location指定的必须是HDFS下的路径，建表时hive不会检验该路径是否有效。hive会加载指定路径下的所有文件。
  ```
* Hive创建内部表时，会将数据移动到数据仓库的指定路径下；若创建外部表，仅记录数据文件所在的存储路径，不对数据文件的位置做任何改变。在删除表的时候，内
  部表所对应的数据文件和元数据会被一起删除，而外部表只删除元数据，不删除数据文件。
  
#### 12.LIKE关键字与复制表结构
```
Like关键字允许用户复制现有表的表结构，但是不复制数据。
HQL语句示例： create [external] table [if not exist] [db_name.]table_name like existing_table;
```

#### 13.CLI常用显示命令
```
1.show tables：显示当前数据库的所有表
2.show databases|schemas：显示所有数据库
3.show partitions {?table_name}：显示表分区信息
4.show functions：显示当前版本hive支持的所有方法
5.desc extended {?table_name}：查看表信息
6.desc formatted {?table_name}：查看表信息（格式化后的,展示美观）
7.describe database {?database_name}：查看数据库相关信息
```  

#### 14.LOAD操作
```
1.在将数据加载到表中时，Hive不会进行任何转换。加载操作是将数据文件移动到与Hive表对应的位置的纯复制/移动操作。
2.语法结构：load data [local] inpath 'filepath' [overwrite] into table table_name [partiton(partcol1=val1,partcol2=val2,...)]
  其中，
  filepath可以是
  相对路径，例如： project/data1
  绝对路径，例如：/usr/hive/project/data1
  完整URI，例如：hdfs://namenode:9000/usr/hive/project/data1
  filepath可以引用一个文件(在这种情况下，hive将文件移动到表所对应的文件目录中)，或者是一个目录(在这种情况下，hive将把该目录中所有文件移动
  到表所对应的文件目录中)。
  local
  如果指定了local，load命令将在本地文件系统中查找文件路径，local指的是Hive服务端所在的机器。
  load命令会将filepath中的文件复制到目标文件系统中。目标文件系统由表的位置属性决定。被复制的数据文件移动到表的数据对应的位置。如果没有指定
  local关键字，且filepath指向的是一个完整的URI，hive会直接使用这个URI。否则，如果没有指定schema或者authority,hive会使用在hadoop配置文件
  中定义的schemas和authority，fs.default.name指定了NameNode的URI。
  overwrite
  如果使用了overwrite关键字，则目标表(或者分区)中的内容会被删除，然后再将filepath指向的文件/目录中的内容添加到表/分区中。如果目标表(或者分区)
  已经有一个文件，并且文件名和filepath中的文件名冲突，那么现有的文件会被新文件所替代。
```

#### 15.INSERT操作
```
1.Hive中insert主要是结合select查询语句使用，将查询结果插入到表中，例如：insert overwrite table t1 select * from t2； 。
2.需要保证查询结果列的数目和要插入的数据表的列的数目一致。
3.如果查询出来的数据类型和要插入的表的数据类型不一致，hive将会尝试进行转换，但是并不保证转换一定成功，转换失败的数据将会是NULL。
4.可以将一个表查询出来的数据插入到原表中，结果相当于自我复制了一份数据。
5.多重插入(Multi inserts)： 将表t1的id字段与name字段的值分别插入表t2与t3
      from t1 
      insert overwrite table t2 select id
      insert overwrite table t3 select name;
6.动态分区插入(Dynamic partition inserts)：动态分区是通过位置来指定分区值的。原始表select出来的值和输出partition的值的关系
  仅仅是通过位置来对应的，和HQL语句中的名称并没有关系。
7. 开启动态分区功能：set hive.exec.dynamic.partition=true, 默认是false；
   设置动态分区功能的模式：set hive.exec.dynamic.partition.mode=nonstrict, 默认是strict，表示必须指定至少一个分区为静态分区，
   nonstrict模式表示允许所有的分区字段都可以使用动态分区。
8.(1).创建目标表：create table t1(ip string) partitioned by(month string,day string);
  (2).动态插入分区：insert overwrite table t1 partition (month,day) select ip,substr(datee,1,7) as mon,datee from t2; 。 
```

#### 16.DIRECTORY关键字与导出表数据
```
HQL语法结构：
1.insert overwrite [local] directory 'path' select...from...,其中使用local时，表示导入到本地文件系统(Hive服务端所在的机器)，否则
  就是HDFS文件系统。
2.多重导出：将source表的数据分别导出到目录path1与path2
  from source
  insert overwrite [local] directory 'path1' select...from...
  insert overwrite [local] directory 'path2' select...from...
3.数据写入到文件系统时会进行文本序列化，且每列用^A来区分，\n为换行符。
```






