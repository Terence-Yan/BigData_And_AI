#### 1.简述HDFS写文件的过程
```
1.通过FileSystem对象创建一个文件对象
2.通过RPC在NameNode上创建一个文件对象
3.NameNode对要创建的文件执行检查，如该文件是否存在以及客户端是否有创建权限等
4.检查通过，NameNode就会为该文件创建生成一条记录；否则，向客户端抛出一个IO异常，提示文件创建失败
5.客户端确认可以创建该文件，开始与DataNode建立通信，并将数据写入
6.待客户端收到数据写入完毕的确认消息后，关闭资源，并向NameNode发送文件写入完毕的消息
```

#### 2.简述HDFS读文件的过程
```
1.通过FileSystem对象打开要读取的文件
2.通过RPC从NameNode上获取该文件所涉及的所有block及其副本的位置
3.通过InputStream对象开始依次读取所有的block
4.数据读取完毕，关闭资源
```
#### 3.hadoop集群中涉及的守护进程有哪些？
```
NameNode、DataNode、SecondaryNameNode、
```

#### 4.简述MapReduce(V1.0)运行的工作原理
```
1.JobClient开始运行作业
2.JobClient向jobtracker请求一个新的作业ID，并检查作业的输出说明以及计算作业的输入分片
3.将运行作业所需资源(包括作业JAR文件、配置文件和计算所得的输入分片)复制到HDFS
4.JobClient通知jobtracker作业准备执行
5.jobtracker创建一个正在运行的作业对象
6.作业调度器从共享文件系统获取已经计算好的输入分片，并为每个分片创建一个map任务
7.jobtracker通过心跳机制与tasktracker进行通信，并为tasktracker分配任务
8.tasktracker获取任务所需的所有文件(包括作业JAR文件、配置文件等)
9.tasktracker新建一个TaskRunner实例，TaskRunner启动一个新的JVM来运行每个任务。
```

#### 5.简述MapReduce(V2.0--YARN)运行的工作原理
```
1.客户端通过Job实例开始运行作业
2.Job实例向RM请求一个新的作业ID，并检查作业的输出说明以及计算作业的输入分片
3.Job实例将运行作业所需资源(包括作业JAR文件、配置文件和计算所得的输入分片)复制到HDFS
4.Job实例通过RPC调用RM的submitApplication()方法提交作业
5.RM将作业请求传递给调度器，调度器分配一个容器，并在该容器中启动应用程序的master进程(即AM)
6.AM对作业进行初始化
7.AM接受来自共享文件系统的在客户端计算的输入分片
8.如果作业不适合作为uber任务运行，AM将向RM为该作业中的所有任务申请容器资源
9.RM的调度器为任务分配容器后，AM就通过与NM通信来启动容器
10.将任务需要的资源本地化，包括作业的配置、JAR文件和所有来自分布式缓存的文件
11.运行map任务或reduce任务
```
