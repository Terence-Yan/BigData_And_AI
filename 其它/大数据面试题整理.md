#### 1.简述HDFS写文件的过程
```
1.通过FileSystem对象创建一个文件对象
2.通过RPC在NameNode上创建一个文件对象
3.NameNode对要创建的文件执行检查，如该文件是否存在以及客户端是否有创建权限等
4.检查通过，NameNode就会为该文件创建生成一条记录；否则，向客户端抛出一个IO异常，提示文件创建失败
5.客户端确认可以创建该文件，开始与DataNode建立通信，并将数据写入
6.待客户端收到数据写入完毕的确认消息后，关闭资源，并向NameNode发送文件写入完毕的消息
```

#### 2.简述HDFS读文件的过程
```
1.通过FileSystem对象打开要读取的文件
2.通过RPC从NameNode上获取该文件所涉及的所有block及其副本的位置
3.通过InputStream对象开始依次读取所有的block
4.数据读取完毕，关闭资源
```
#### 3.hadoop集群中涉及的守护进程有哪些？
```
NameNode、DataNode、SecondaryNameNode、
```

#### 4.简述MapReduce运行的工作原理
```
1.Job客户端开始运行作业
2.向jobtracker请求一个新的作业ID，并检查作业的输出说明以及计算作业的输入分片
3.将运行作业所需资源(包括作业JAR文件、配置文件和计算所得的输入分片)复制到HDFS
4.通知jobtracker作业准备执行
5.jobtracker创建一个正在运行的作业对象
6.作业调度器从FS获取已经计算好的输入分片，并为每个分片创建一个map任务
```
