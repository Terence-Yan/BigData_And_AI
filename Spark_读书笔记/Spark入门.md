#### 1.Spark的日志配置
Spark通过在conf目录(位于安装目录里面)下创建一个名为log4j.properties的文件来管理日志设置。Spark开发者们已经在Spark中加入了一个日志设置文件的
模板，叫做log4j.properties.template。你只需要把这个日志设置模板文件复制一份到conf/log4j.properties来作为日志设置文件。

#### 2.Spark的基本计算单元--RDD
在Spark中，我们通过对分布式数据集的操作来表达我们的计算意图，这些计算会自动地在集群上并行进行。这样的数据集被称为 ***弹性分布式数据集*** 
(resilient distributed dataset),简称RDD。RDD是Spark 对分布式数据和计算的基本抽象。</br>
RDD其实就是分布式的元素集合。在Spark中，对数据的所有操作不外乎**创建RDD**、**转化已有的RDD**以及**调用RDD操作进行求值**。而在这一切的背后，Spark会**自动**将RDD中的数据分发到集群上，并将操作并行化执行。

#### 3.Spark应用的驱动器程序
从上层来看，每个Spark应用都有一个驱动器程序(driver program)来发起集群上的各种并行操作。驱动器程序包含应用的main函数，并定义了集群上的分布式数据集，还对这些分布式数据集应用了相关操作。驱动器程序通过一个 **SparkContext** 对象来访问Spark。这个对象代表对计算机群的一个连接。

#### 4.RDD的特性及可存储的数据类型
Spark中的RDD就是一个**不可变**的分布式对象集合。每个RDD都被分为多个**分区(partition)** ，这些分区运行在集群中的不同节点上。RDD可包含Python、Java、Scala中任意类型的对象，甚至可以包含用户自定义的对象。

#### 5.RDD的两种操作类型
RDD支持两种类型的操作：**转化操作(transformation)** 和 **行动操作(action)** 。转化操作会由一个RDD生成一个新的RDD。而行动操作，会对RDD计算出一个结果，并把结果返回到驱动器程序中，或把结果存储到外部存储系统(如HDFS)中。因此，你可以通过返回值类型来区分这两种操作：**transformation操作返回的是RDD，而action操作返回的是其他的数据类型**。

#### 6.转化操作与行动操作的区别——惰性计算
转化操作和行动操作的区别在于Spark计算RDD的方式不同。虽然可以在任何时候定义新的RDD，但Spark只会 **惰性计算** 这些RDD。它们只有第一次在一个行动操作中用到时，才会真正计算。

#### 7.RDD的重用与缓存
默认情况下，Spark的RDD会在你每次对它们进行行动操作时重新计算。如果想在多个行动操作中重用同一个RDD，可以使用 **RDD.persist()** 让Spark把这个RDD缓存下来。在第一次对持久化的RDD计算之后，Spark会把RDD的内容保存到内存中(以分区方式存储到集群中的各个机器上)，这样在之后的行动操作中，就可以重用这些数据了。我们也可以把RDD缓存到磁盘上而不是内存中。默认不进行持久化可能显得有些奇怪，不过这对于大规模数据集是很有意义的：如果不会重用该RDD，我们就没有必要浪费存储空间，Spark可以直接遍历一遍数据然后计算出结果。</br>
***注：在任何时候都能进行重算是我们为什么把RDD描述为“弹性”的原因。当保存RDD数据的一台机器失败时，Spark还可以使用这种特性来重算出丢掉的分区，这一过程对用户是完全透明的。***

#### 8.cache()与使用默认存储级别调用persist()是一样的

#### 9.RDD的两种创建方式
Spark提供了两种创建RDD的方式：读取外部数据集，以及在驱动器程序中对一个集合进行并行化。</br>
创建RDD最简单的方式就是把程序中一个已有的集合传给SparkContext的parallelize()方法。这种方式在学习Spark时非常有用，它让你可以在shell中快速创建出自己的RDD，然后对这些RDD进行操作。不过，需要注意的是，除了开发原型和测试时，这种方式用得并不多，毕竟这种方式需要把你的整个数据集先放在一台机器的内存中。
```
例：Scala中的parallelize()方法
val lines = sc.parallelize(List("pandas","i like pandas"))
```
更常用的方式是从外部存储中读取数据来创建RDD。
```
例：Scala中的textFile()方法
val lines = sc.textFile("/path/README.md")
```
#### 10.RDD的谱系图
通过转换操作，你从已有的RDD中派生出新的RDD，Spark会使用 **谱系图(lineage graph)** 来记录这些不同RDD之间的依赖关系。Spark需要用这些信息来按需计算每个RDD，也可以依靠谱系图在持久化的RDD丢失部分数据时恢复所丢失的数据。

#### 11.惰性计算
惰性求值意味着当我们对RDD调用转化操作时，**操作不会立即执行**。相反，Spark会在内部记录下所要执行的操作的相关信息。我们不应该把RDD看作存储着特定数据的数据集，而最好把每个RDD当作我们通过转化操作构建出来的、记录如何计算数据的指令列表。把数据读取到RDD的操作也同样是惰性的。因此，当我们调用sc.textFile()时，数据并没有读取进来，而是在必要时才会读取。和转化操作一样的是，读取数据的操作也有可能会多次执行。</br>
Spark使用惰性求值，这样就可以把一些操作合并到一起来减少计算数据的步骤。在类似Hadoop MapReduce的系统中，开发者常常花费大量时间考虑如何把操作组合到一起，以减少MapReduce的周期数。而在Spark中，**写出一个非常复杂的映射并不见得能比使用很多简单的连续操作获得好很多的性能**。因此，用户可以用更小的操作来组织他们的程序，这样也使这些操作更容易管理。

#### 12.Spark的缓存类型
**org.apache.spark.storage.StorageLevel中的持久化级别(表-1)** </br>
<table><tr><th>级别</th><th>使用的空间</th><th>CPU时间</th><th>是否在内存中</th><th>是否在磁盘上</th><th>备注</th></tr><tr><td>MEMORY_ONLY</td><td>高</td><td>低</td><td>是</td><td>否</td><td></td></tr><tr><td>MEMORY_ONLY_SER</td><td>低</td><td>高</td><td>是</td><td>否</td><td></td></tr><tr><td>MEMORY_AND_DISK</td><td>高</td><td>中等</td><td>部分</td><td>部分</td><td>如果数据在内存中放不下，则溢写到磁盘上</td></tr><tr><td>MEMORY_AND_DISK_SER</td><td>低</td><td>高</td><td>部分</td><td>部分</td><td>如果数据在内存中放不下，则溢写到磁盘上。在内存中存放序列化后的数据</td></tr><tr><td>DISK_ONLY</td><td>低</td><td>高</td><td>否</td><td>是</td><td></td></tr>
</table>
</br>
```
 注：如有必要，可以通过在存储级别的末尾加上“_2”来把持久化数据存为两份。
```

#### 13.Spark的默认缓存
出于不同的目的，我们可以为RDD选择不同的持久化级别(如表-1所示)。在Scala和Java中，默认情况下persist()会把数据**以序列化的形式缓存在JVM的堆空间中**。在Python中，我们会**始终**序列化要持久化存储的数据，所以持久化级别**默认值就是以序列化后的对象存储在JVM堆空间中**。当我们把数据写到磁盘或者堆外存储上时，也总是使用序列化后的数据。
```
注：persist()调用本身不会触发强制求值。
```

#### 14.Spark中缓存过多的解决方案
如果要缓存的数据太多，内存中放不下，Spark会自动利用 **最近最少使用(LRU)** 的缓存策略把最老的分区从内存中移除。对于仅把数据存放在内存中的缓存级别，下一次要用到已经被移除的分区时，这些分区就需要重新计算。但是对于使用内存与磁盘的缓存级别的分区来说，被移除的分区都会写入磁盘。不论哪一种情况，都不必担心你的作业因为缓存了太多数据而被打断。不过，缓存不必要的数据会导致有用的数据被移除内存，带来更多重算的时间开销。最后，RDD还有一个方法叫做**unpersist()** ，调用该方法可以手动把持久化的RDD从缓存中移除。




