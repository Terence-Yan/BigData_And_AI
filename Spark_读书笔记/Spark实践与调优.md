#### 1.应该用什么类型的硬件来搭建Spark集群？
Spark是一个内存(in-memory)计算网格，了解这一点很重要。因此，为实现效率的最大化，强烈建议把系统作为一个整体，在Spark框架内**留足内存**，以满足可能的
最大工作负载(或者数据集)的需要。并不是说不能在以后调整集群规模，但是若能提前规划会更好，对大公司来说尤其应该如此，因为在大公司里订单的采购往往需要
数周或数月的时间。

#### 2.Spark应用中内存的估计
这里有必要再强调一下内存的概念，当你计算所需要的内存大小时，要明白这种计算**并不是一对一**的关系。也就是说，对于给定的 1TB 数据集，实际需要的内存
不止 1TB。这是因为在Java里从一个数据集中创建对象时，这个对象通常比原来的数据元素大得多，是它的数倍。将这个膨胀倍数与所创建的对象数相乘，就能更准确
地估计出系统完成给定任务所需要的内存大小。

#### 3.Spark集群中，每个物理机应该设定多少个CPU核？
这个问题很难有完整的答案，因为一旦数据负载规范地加载到内存，应用程序通常会受到**网络或者CPU**的掣肘。这就是说，最简单的解决方案就是用一个相对小的
数据集来测试你的Spark程序，弄清楚到底是网络还是CPU在制约着程序，然后制定相应的方案。

#### 4.云的目的是为用户和机构提供可按需启用和按需扩展的机器集群。

#### 5.Spark适用的应用场景——ETL
Spark并不是所有任务都适用。因为Spark本质上是参照MapReduce范式设计的，它的长处是数据的**抽取、转换和加载**操作(Extract、Transform、Load，
三者合称为ETL)。这些处理方式通常被称为批处理——以分布式的方式高效地处理大量数据。**批处理的缺点是通常会引入较大的延迟**。尽管Spark开发人员花费
了很多精力来提升Spark Streaming模式，但是它依然只能做到**秒级**的计算。因此，对于真正的低延迟、高吞吐量的应用来说，Spark并不是一个合适的工具。
对于很多应用场景，Spark最擅长的还是处理典型的ETL工作负载。

#### 6.Spark中的主要资源
总的来说，在Spark生态系统中，主要关注三种类型的资源：磁盘存储、CPU和内存。

#### 7.Spark应用的并行度
当构建Spark应用时，把CPU核的数量和程序的并行度联系起来，或者与它能同时执行的任务关联起来，也是很有帮助的。Spark是建立在RDD上的，RDD是一种抽象，
它把分布式数据集看做一个包含多个分区的单一实体。在Spark中，**一个Spark任务(task)将在一个CPU核上处理一个RDD的一个分区**。因此，程序的并行度基本
上取决于数据的分区数以及可用的CPU核数。

#### 8.Spark中内存的分配方式
* 内存对所有Spark应用而言几乎都是至关重要的。通常来说，集群管理器分配内存的方式与分配CPU核这样的离散资源的方式是一样的。在集群中可用的内存总量被
分解成块(block)或者容器(container)，然后这些容器被分配给特定的应用。通过这种方式，集群管理器可以公平地分配内存和调度资源，避免进程被饿死。
* 大多数应用程序需要依据Spark程序中执行的**RDD转换**做某种程度的**调优**，来恰当地平衡内存需求。一个**内存配置不当**的Spark应用程序，运行起来
可能会很低效。

#### 9.内存动态自动调优功能
从Spark1.6开始，引入了内存动态自动调优功能。在1.6版本中，Spark会自动调整分配给shuffle操作和缓存的**内存比例**，同时也会调整分配的**内存总量**。
这样就能把更大的数据集装入到较小的内存中，而且无须对内存参数进行大量的调优，使编写程序更容易。

#### 10.Spark应用中的文件应该被切分成多大？
* 众所周知，在HDFS上每个文件都是按块存储的。当Spark读取这些文件的时候，**每个HDFS块会映射到一个Spark分区**(partition)。对每个分区，将启动一个
Spark任务(task)来读取和处理。如果你有足够的资源，而且数据分区得当，通常会给高并行计算带来很大好处。然而，任务太多会产生较高的调度开销，因此应当尽量
**避免不必要的调度**。总之，读取的文件数太多会导致启动的任务数相应增加，也会带来大量的任务调度开销。
* 除了大量的任务被启动，读取大量小文件也增加了**打开文件所带来的时间开销**。还有一点:所有文件路径都是在driver上处理的。如果文件包含很多小文件，
driver可能面临内存压力。
* 另一方面，如果数据集是由一组庞大的文件组成，必须确保这些文件是可切分的；否则，必定由单独的任务来处理这些文件，这将需要一个非常大的分区，也会大大
降低程序性能。

#### 11.文件的压缩与可切分
一个压缩文件是否支持可切分，不仅取决于压缩编解码器，还取决文件的格式。如对支持块结构的文件格式，如Sequence文件或ORC文件，使用不可切分的编解码器，
那么每个块都会被压缩。在这种情况下，Spark会对每一个块并行启动任务。所以，你可以认为它们是可分的。但是，另一方面，如果用它们压缩文本文件，那么整个
文件会被压缩到一个块中，因此对于每个文件都会有一个任务被启动。

#### 12.Spark中JSON文件的处理
* 对JSON文件的读取和处理，SparkSQL有一个专门的方法。其中一个好处是可以让SparkSQL根据数据集推断或者通过编程方式指定schema。如果你提前知道了
schema，建议提供出来，省得Spark**再次扫描整个输入文件去确定schema**。这种方式的另一个好处是允许你自己**决定需要处理的字段**。如果JSON文件
中有很多你并不需要的字段，你可以仅指定相关的字段，其它的将会被忽略掉。
```
   val schema = new StructType(Array(new StructField("name", StringType, false), new StructField("age", IntegerType, false)))
   val specifiedSchema = sqlContext.jsonField("file.json", schema)
```
* 上面处理JSON文件的方式假设**每一行都有一个JSON对象**。如果一些JSON对象缺失一些字段，那么这些字段会被默认替换为null值。在推断schema时，
如果有一些错误的输入，SparkSQL会创建一个名为_corrupt_record的新列。这些错误的输入会在这一列中存储它们的数据，而其它列都为null值。

#### 13.Sequence文件
Sequence文件是一种常用的文件格式，由**二进制键值对**组成，这些键值对必须是Hadoop **Writable接口**的子类。因为有**同步标记的特性**，它们
在分布式处理中很受欢迎。有这些特性，你就能找到记录的边界来做并行处理。**Sequence文件是一种十分高效的数据存储格式，因为它能被高效地压缩及解压**。

#### 14.Avro文件
Avro文件格式是一种依赖于schema的二进制数据格式。当以Avro格式存储数据时，**schema总是与数据一起存储**。这个特点使得在不同的应用程序中都可以读取
Avro文件。

#### 15.Parquet文件
* Parquet文件格式是一种**支持嵌套数据结构的列式文件格式**。列式存储格式非常适用于**聚合查询**，因为从磁盘中读取数据时仅返回需要的列。Parquet文件
支持高效地压缩和编码schema，因为它们可以按列指定。这正是使用这种文件格式能减少磁盘I/O操作、节省更多存储空间的原因。
* SparkSQL提供专门的方法来读写保存数据schema的Parquet文件，并且Parquet文件格式**支持schema演化**，起初可以只有几列，然后按需添加更多的列。
Parquet会自动检测这些schema差异并自动合并。不过，在非必要情况下应避免schema合并，因为**该操作严重影响性能**。下面的例子演示了如何读取
Parquet文件并启用schema合并功能：
```
  val parquetDF = sqlContext.read.option("mergeSchema","true").parquet("parquetFolder")
```
* 在SparkSQL中，Parquet Datasource能够检测数据是否已分区并确定分区。这对于数据分析是一项重要的优化，因为在一次查询中，只有需要的分区才会根据查询
语句中的断言(predicate)被扫描。
* 从SparkSQL最佳实践的角度，鼓励使用Parquet文件格式。

#### 16.计算资源的稀缺性
分布式系统中的很多挑战来源于要管理系统运行所需的资源。根本问题是资源的稀缺性——资源是有限的，然而有众多的应用程序在执行时需要这些资源。
如果没有一个系统来管理和调度资源，是无法实现分布式计算的。

#### 17.Spark中数据的组织与传输
为了给用户提供简洁而直观的界面，Spark进行了一些抽象，Spark就是建立在这些抽象概念之上的。其中，核心抽象为RDD或DataFrame，用于将原本存储在
分布式环境中的大量数据转换为**隐藏了数据分布特性**的单个对象。从底层看，Spark会处理不同机器间的数据传输而**无须用户手动组织数据**，因此可
以把精力和时间放在思考应用程序自身的逻辑上，使创建复杂的应用更简单。

#### 18.集群管理器的目的是为需要执行的逻辑代码分配物理资源。

#### 19.应用系统的可用性
可用性是指一个系统在任意场景下都可运行，这一需求很重要，尤其是在生产环境中。一个系统如果有个别组件出现故障，但是仍然能运行且对外不中断服务，
就可称其为**高可用的系统**。正是建立一个不会发生灾难性崩溃系统的愿望和这类系统动态增减资源的需求，推动了现代集群管理工具的设计。

#### 20.集群管理器与物理机自带操作系统的关系
通常来说，集群管理器不会取代单机上的操作系统。相反，集群管理器好比是一个跨机器的操作系统，在各台机器上，利用本地操作系统对本地资源和物理硬件
实现更细粒度的控制和访问。因此，集群管理器主要处理更一般的任务：公平地调度资源。

#### 21.Driver
* 从高一点的层级来看，一切Spark应用都是由driver开始的。
* driver是**负责启动**和**管理运行Spark应用**的进程。确切地说，driver是维护所有计算节点(**worker node**)的连接的实体，并将Spark应用的逻辑代码
转换成在集群中某处执行的物理命令。作为主进程，driver履行许多职责。
* 首先且最重要的是，driver维护Spark运行的**上下文**(context)——一种程序状态，允许Spark给**executor**分配任务(task)，同时维护某些内部结构，譬如
**累加器**和**广播变量**。这个上下文跟踪应用程序的设置与可用资源。
* 其次，driver处理与集群管理器的**通信**，**请求资源**以及**执行Spark应用**。一旦这些资源可用，driver就会根据Spark应用的逻辑代码创建一个执行计划
(**execution plan**)，把它提交到所分配的worker节点上。该执行计划本身是一个包括若干行动操作(action)和转换操作(transformation)的**有向无环图**
(Directed Acyclical Graph, **DAG**)。Spark优化这个DAG来**减少数据的传输**，然后一个名为 **DAGScheduler** 的内部结构进一步将此DAG分解为一个个
**stage**(步骤)，再分解为task。一个stage就是一组转换操作，它们将作用于RDD中的数据。
* Spark中的数据被分解成很多**分区**(partition)，这意味着如果只有一个完整的数据集，Spark将无法一次处理完。这份数据被分成若干小块，各块允许分开处理
以增加并行度。当DAGScheduler把一个stage细分成若干个task时，**它为RDD的每个分区创建一个对应的新task**，这样每个task执行的都是相同的操作但处理的
却是这份数据的不同部分。**每个任务执行的结果最终组成一个RDD**。
* DAGScheduler将DAG细分成task，然后**TaskScheduler**(任务调度器)在集群中调度这些task。TaskScheduler了解资源与数据局部性的限制条件，将task分配
给相应的executor。一旦TaskScheduler决定了在哪里执行task，所有DAG对应的transformation操作以及转换闭包(transformation closure)就被**序列化**，
并通过网络传给一个worker节点，在该节点上由合适的executor去执行必要的操作。TaskScheduler也**负责重启失败的或长时间无法正常完成运行的task**。

#### 22.workers与executors
* 在一个Spark集群中，worker节点**是实际运行executor和task的物理机器**。用户永远**不会直接与worker节点交互**，但是在底层，集群管理器负责与各个
worker节点通信并处理资源的分配。每个worker节点都有**固定的可用资源**，这些资源都被显式地分配给集群管理器。由于worker节点可以**运行多个应用**(不
仅仅是Spark)，所以限制集群管理器占用的资源，才能保证多租户的使用以及其他程序的并发执行。
* 在一个Spark集群中，每个worker节点可以运行一个或多个executor，executor是一种抽象，让Spark程序可配置地执行。**每个executor运行一个Java虚拟机**，
因此本身有**固定量的资源**。分配给executor的内存和CPU核等资源，以及所有的executor数，在Spark中都是可调参数，对应用程序的执行有重大影响。
* Spark的**并行度取决于其配置**。例如，如果你只分配了一个executor，该executor只有两个核，那么Spark只能并行运行两个进程，因为一个核一次只能运行
一个进程。此外，对于一个操作，你可用的**内存量最多只能为**：该executor可用的内存总量除以该executor中运行的进程数所得的商。因此，如果给每个executor
分配8GB内存、8个CPU核，每次转换最多可以有1GB内存可用。如果这些设置没有正确地配置，而且底层数据集没有被划分成足够小的数据组(chunk)，Spark操作数据
时可能会耗尽内存。这还可能会导致内存错误，或因为数据在磁盘和内存中来回传输而影响性能。
* 当运行一个系统时，找出**合适的配置平衡是关键**，因此必须仔细考虑这个系统的可用资源以及集群管理器的配置。此外，你还必须理解executor如何与系统其它
组件进行交互。例如，考虑下面两个配置项：
```
  --num-executors 5, --executor-cores 10
  --num-executors 10, --executor-cores 5
```
从HDFS读取数据时，由于数据在HDFS中的消费方式，第二种设置的性能可能更好。HDFS可支持的并行操作数与存储在该数据节点上的HDFS块数量有关。因为需要处理的
数据被拆分到多个节点上，所以根据数据规模及其分布形式，你可以通过增加executor获得更高的性能，而不是让多个核去读取在一个节点上的同一片小数据。
* 作为一个计算框架，Spark需要为分配的内存定义一个结构。在操作系统中，内存有堆和栈之分。栈是用于跟踪程序状态、静态分配内存以及本地上下文的内存池。
堆是用于为新对象动态分配内存的内存池。
* 一个executor可能有多个task，它们共享这个结构化内存池。让多个task使用一个分配的资源块，可以减少一些特定的Spark操作开销。例如，用于支持全局数据共享
的**广播变量，就是在每个executor而不是每个task上复制的**。executor越多，每个executor拥有的核越少，可能会导致不必要的数据冗余。













